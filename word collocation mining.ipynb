{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word collocation mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_filepath = \"tweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "tweetcount = 0\n",
    "with open(tweet_filepath) as file:\n",
    "    for line in file:\n",
    "        tweetcount +=1\n",
    "print (tweetcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itemset_frequency(tweet_filepath):\n",
    "    item_freq = {}\n",
    "    with open(tweet_filepath) as f:\n",
    "        for line in f:\n",
    "            text = line.strip().split()\n",
    "            items = [x for x in text if not x.startswith(\"@\") and not x.startswith(\"#\")]\n",
    "            for item in set(items): #ignore duplicate words in a line\n",
    "                if item not in item_freq:\n",
    "                    item_freq[item]  =1\n",
    "                else:\n",
    "                    item_freq[item] +=1\n",
    "    return item_freq\n",
    "\n",
    "def get_bigram_frequency(tweet_filepath):\n",
    "    bigram_freq = {}\n",
    "\n",
    "    with open(tweet_filepath) as f:\n",
    "        for line in f:\n",
    "            bigram_list = []\n",
    "            text = line.strip().split()\n",
    "            for i in range(len(text)-1):\n",
    "                if not text[i].startswith('#') and \\\n",
    "                   not text[i].startswith('@') and \\\n",
    "                   not text[i+1].startswith('#') and \\\n",
    "                   not text[i+1].startswith('@'):\n",
    "                    bigramset = (text[i],text[i+1])\n",
    "                    bigram_list.append(bigramset)\n",
    "            for bigramset in set(bigram_list):\n",
    "                if bigramset not in bigram_freq:\n",
    "                    bigram_freq[bigramset] =1\n",
    "                else:\n",
    "                    bigram_freq[bigramset] +=1\n",
    "    return bigram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save item frequency\n",
    "itemset= get_itemset_frequency(tweet_filepath)\n",
    "\n",
    "#Save word pair frequency\n",
    "bigram_freq = get_bigram_frequency(tweet_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 161290\n",
      "to 108698\n",
      "a 108676\n",
      "the 99682\n",
      "you 86025\n",
      "me 80856\n",
      "my 69715\n",
      "and 67236\n",
      "is 58984\n",
      "in 48043\n"
     ]
    }
   ],
   "source": [
    "for item, freq in sorted(itemset.items(), key = lambda x: x[1], reverse = True)[:10]:\n",
    "    print(item, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2198740"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in', 'the') 10373\n",
      "('i', \"don't\") 9304\n",
      "('i', 'love') 9217\n",
      "('to', 'be') 8429\n",
      "('i', 'just') 7850\n",
      "('i', 'have') 7103\n",
      "('i', 'want') 6721\n",
      "('if', 'you') 6626\n",
      "('follow', 'me') 6053\n",
      "('and', 'i') 6030\n"
     ]
    }
   ],
   "source": [
    "for bigram, freq in sorted(bigram_freq.items(), key = lambda x: x[1], reverse = True)[:10]:\n",
    "    print(bigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual information calculation in each cell \n",
    "def mi_cell_formula_calculate(bigramfreq,freq_x,freq_y,totalcount):\n",
    "    if bigramfreq == 0:\n",
    "        return 0\n",
    "    else:    \n",
    "        mi_cell = bigramfreq / totalcount * math.log(bigramfreq/totalcount/((freq_x/totalcount)*(freq_y/totalcount)))\n",
    "        return mi_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pointwise mutual information\n",
    "def Pointwise_mutual_information_calculation(unigram,bigram,tweetcount):\n",
    "    pmi_per_bigram={}\n",
    "    for bigramset,bigramfreq in bigram.items():\n",
    "        if bigramfreq <100:\n",
    "            continue\n",
    "        x = bigramset[0]\n",
    "        y = bigramset[1]\n",
    "        freq_x=unigram[x] \n",
    "        \n",
    "        freq_y=unigram[y]\n",
    "        pmi_per_bigram[bigramset]=math.log(bigramfreq/tweetcount/((freq_x/tweetcount)*(freq_y/tweetcount)))\n",
    "    return pmi_per_bigram\n",
    "\n",
    "#Chi-square \n",
    "def Chi_square_calculation(unigram,bigram,tweetcount):\n",
    "    chi2_per_bigram={}\n",
    "    for bigramset,bigramfreq in bigram.items():\n",
    "        if bigramfreq <100:\n",
    "            continue\n",
    "        x,y =bigramset\n",
    "        freq_x =unigram[x]\n",
    "        freq_y =unigram[y]\n",
    "        freq_non_x = tweetcount - freq_x\n",
    "        freq_non_y = tweetcount - freq_y\n",
    "        \n",
    "        expected_value_xy = freq_x * freq_y / tweetcount\n",
    "        expected_value_non_x_y = freq_non_x* freq_y / tweetcount\n",
    "        expected_value_x_non_y = freq_non_y* freq_x / tweetcount\n",
    "        expected_value_non_x_non_y  = freq_non_x * freq_non_y / tweetcount\n",
    "\n",
    "        bigramfreq_non_x_y = freq_y - bigramfreq\n",
    "        bigramfreq_x_non_y = freq_x - bigramfreq\n",
    "        bigramfreq_non_x_non_y = tweetcount - freq_x - freq_y + bigramfreq\n",
    "        chi2_per_bigram[bigramset]=(bigramfreq-expected_value_xy)**2/expected_value_xy +\\\n",
    "                                   (bigramfreq_non_x_y - expected_value_non_x_y) **2/expected_value_non_x_y +\\\n",
    "                                   (bigramfreq_x_non_y - expected_value_x_non_y) **2/expected_value_x_non_y +\\\n",
    "                                   (bigramfreq_non_x_non_y - expected_value_non_x_non_y) **2/expected_value_non_x_non_y \n",
    "    return chi2_per_bigram\n",
    "\n",
    "#Mutual information\n",
    "def mutual_information_calculation(unigram,bigram,tweetcount):\n",
    "    mi_per_bigram = {}\n",
    "    for bigramset,bigramfreq in bigram.items():\n",
    "        if bigramfreq <100:\n",
    "            continue\n",
    "        x,y=bigramset\n",
    "        freq_x=unigram[x]\n",
    "        freq_y=unigram[y]\n",
    "        freq_non_x = tweetcount - freq_x\n",
    "        freq_non_y = tweetcount - freq_y\n",
    "        \n",
    "        bigramfreq_non_x_y = freq_y - bigramfreq\n",
    "        bigramfreq_x_non_y = freq_x - bigramfreq\n",
    "        bigramfreq_non_x_non_y = tweetcount - freq_x - freq_y + bigramfreq\n",
    "        mi_per_bigram[bigramset] = mi_cell_formula_calculate(bigramfreq,freq_x,freq_y,tweetcount)+\\\n",
    "                                   mi_cell_formula_calculate(bigramfreq_non_x_y,freq_non_x,freq_y,tweetcount)+\\\n",
    "                                   mi_cell_formula_calculate(bigramfreq_x_non_y,freq_x,freq_non_y,tweetcount)+\\\n",
    "                                   mi_cell_formula_calculate(bigramfreq_non_x_non_y,freq_non_x,freq_non_y,tweetcount)\n",
    "    return mi_per_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_tweet = Pointwise_mutual_information_calculation(itemset,bigram_freq,tweetcount)\n",
    "\n",
    "chi_tweet = Chi_square_calculation(itemset,bigram_freq,tweetcount)\n",
    "\n",
    "mi_tweet = mutual_information_calculation(itemset,bigram_freq,tweetcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Based on Pointwise mutual information**********\n",
      "('a.jalan2', 'b.tepar')\n",
      "('b.tepar', 'c.ngumpul2')\n",
      "('pengen?', 'a.jalan2')\n",
      "('peanut', 'butter')\n",
      "('a.ya', 'b.gak')\n",
      "('hannah', 'montana')\n",
      "('hobby', 'lobby')\n",
      "('harry', 'potter')\n",
      "('taco', 'bell')\n",
      "('gugu', 'morreu')\n",
      "('warna', 'sepatu')\n",
      "('terlatih', 'sakit')\n",
      "('ashton', 'irwin')\n",
      "('testing', '1404190823')\n",
      "('testing', '1404191460')\n",
      "('atau', 'maingame')\n",
      "('nontonkartun', 'atau')\n",
      "('24', 'horas,')\n",
      "('dengerin', 'lagu')\n",
      "('teen', 'wolf')\n",
      "('ice', 'cream')\n",
      "('calum', 'hood')\n",
      "('restoring', 'awesome')\n",
      "('michael', 'clifford')\n",
      "('buenas', 'noches')\n",
      "('boa', 'noite')\n",
      "('social', 'media')\n",
      "('wide', 'awake')\n",
      "('buenos', 'dias')\n",
      "('low', 'key')\n",
      "('difference', 'between')\n",
      "('sering', 'habis')\n",
      "('udah', 'terlatih')\n",
      "('awesome', 'cars')\n",
      "('sakit', 'hati')\n",
      "('je', 'vais')\n",
      "('hobi', 'main')\n",
      "('pengen', 'bilang')\n",
      "('free', 'agency')\n",
      "('ke', 'haters?')\n",
      "('awkward', 'moment')\n",
      "('puta', 'madre')\n",
      "('luke', 'hemmings')\n",
      "('free', 'agent')\n",
      "('punya', 'sahabat')\n",
      "('lagi', 'pengen?')\n",
      "('tal', 'vez')\n",
      "('habis', 'buat')\n",
      "('hi', 'boys!')\n",
      "('fall', 'asleep')\n",
      "('looking', 'forward')\n",
      "('lebih', 'baik')\n",
      "('fell', 'asleep')\n",
      "('nba', 'free')\n",
      "('ta', 'passando')\n",
      "('falling', 'asleep')\n",
      "('sem', 'sono')\n",
      "('cada', 'vez')\n",
      "('watch', 'this!')\n",
      "('meu', 'deus')\n",
      "('orang', 'lain')\n",
      "('otra', 'vez')\n",
      "('cek', 'dm')\n",
      "('noticias', 'las')\n",
      "('world', 'cup')\n",
      "('um', 'pouco')\n",
      "(\"i'd\", 'rather')\n",
      "('buka', 'puasa')\n",
      "('each', 'other')\n",
      "('pra', 'mim')\n",
      "('bulan', 'puasa')\n",
      "('al', 'pedo')\n",
      "('pulsa', 'kamu')\n",
      "('tweet', 'limit')\n",
      "('saat', 'ini')\n",
      "('years', 'ago')\n",
      "('menurut', 'kamu')\n",
      "('sama', 'seseorang')\n",
      "('hari', 'ini')\n",
      "('new', 'york')\n",
      "('god', 'bless')\n",
      "('o', 'gugu')\n",
      "('las', 'mujeres')\n",
      "('vou', 'dormir,')\n",
      "(\"jack's\", 'new')\n",
      "('un', 'canal')\n",
      "('simply', 'because')\n",
      "('buy', '\"doing')\n",
      "('bilang', 'apa')\n",
      "('las', '24')\n",
      "('new', 'song!')\n",
      "('happy', 'birthday!')\n",
      "('july', '1st')\n",
      "('ha', 'ha')\n",
      "('lebih', 'suka')\n",
      "('al', 'fin')\n",
      "('boys!', 'please')\n",
      "('jacks', 'new')\n",
      "('two', 'weeks')\n",
      "('di', 'dunia')\n"
     ]
    }
   ],
   "source": [
    "# sort bigrams in pmi_per_bigram by their PMI from highest to lowest. Show the top 100 bigrams.\n",
    "print(\"**************Based on Pointwise mutual information**********\")\n",
    "pmi_top = []\n",
    "for bigram,freq in sorted(pmi_tweet.items(), key = lambda x: x[1], reverse = True)[:100]:\n",
    "    print(bigram)\n",
    "    pmi_top.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.tepar: 147\n",
      "c.ngumpul2: 147\n",
      "a.jalan2: 147\n",
      "b.tepar: 147\n",
      "pengen?: 159\n",
      "a.jalan2: 147\n",
      "peanut: 140\n",
      "butter: 174\n",
      "a.ya: 210\n",
      "b.gak: 191\n",
      "hannah: 205\n",
      "montana: 135\n",
      "hobby: 219\n",
      "lobby: 161\n",
      "harry: 399\n",
      "potter: 114\n",
      "taco: 351\n",
      "bell: 273\n",
      "gugu: 171\n",
      "morreu: 376\n",
      "warna: 412\n",
      "sepatu: 136\n",
      "terlatih: 234\n",
      "sakit: 653\n",
      "ashton: 664\n",
      "irwin: 161\n",
      "testing: 712\n",
      "1404190823: 349\n",
      "testing: 712\n",
      "1404191460: 301\n",
      "nontonkartun: 114\n",
      "atau: 729\n",
      "atau: 729\n",
      "maingame: 114\n",
      "24: 794\n",
      "horas,: 406\n",
      "dengerin: 288\n",
      "lagu: 377\n",
      "teen: 736\n",
      "wolf: 663\n"
     ]
    }
   ],
   "source": [
    "#Frequency of word in top20 bigram of pmi_tweet\n",
    "for bgram in pmi_top[:20]:\n",
    "    for x in bgram:\n",
    "        print(\"{}:\".format(x),itemset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Based on Chi-square **********\n",
      "('b.tepar', 'c.ngumpul2')\n",
      "('a.jalan2', 'b.tepar')\n",
      "('pengen?', 'a.jalan2')\n",
      "('luke', 'hemmings')\n",
      "('a.ya', 'b.gak')\n",
      "('teen', 'wolf')\n",
      "('taco', 'bell')\n",
      "('testing', '1404190823')\n",
      "('hobby', 'lobby')\n",
      "('24', 'horas,')\n",
      "('peanut', 'butter')\n",
      "('testing', '1404191460')\n",
      "('hannah', 'montana')\n",
      "('ice', 'cream')\n",
      "('terlatih', 'sakit')\n",
      "('michael', 'clifford')\n",
      "('boa', 'noite')\n",
      "('gugu', 'morreu')\n",
      "('free', 'agency')\n",
      "('harry', 'potter')\n",
      "('buenas', 'noches')\n",
      "('ashton', 'irwin')\n",
      "('calum', 'hood')\n",
      "('warna', 'sepatu')\n",
      "('fall', 'asleep')\n",
      "('social', 'media')\n",
      "('nontonkartun', 'atau')\n",
      "('atau', 'maingame')\n",
      "('restoring', 'awesome')\n",
      "('sakit', 'hati')\n",
      "('dengerin', 'lagu')\n",
      "('udah', 'terlatih')\n",
      "('wide', 'awake')\n",
      "('from', '5sos')\n",
      "('happy', 'birthday')\n",
      "('hemmings', 'from')\n",
      "('buenos', 'dias')\n",
      "('please', 'follow')\n",
      "('awesome', 'cars')\n",
      "('new', 'song')\n",
      "('difference', 'between')\n",
      "('looking', 'forward')\n",
      "('noticias', 'las')\n",
      "('watch', 'this!')\n",
      "('each', 'other')\n",
      "('awkward', 'moment')\n",
      "('hobi', 'main')\n",
      "('go', 'buy')\n",
      "('sering', 'habis')\n",
      "('low', 'key')\n",
      "('right', 'now')\n",
      "('jacks', 'new')\n",
      "('lebih', 'baik')\n",
      "('je', 'vais')\n",
      "('nba', 'free')\n",
      "('simply', 'because')\n",
      "('pengen', 'bilang')\n",
      "('world', 'cup')\n",
      "('at', 'least')\n",
      "(\"i've\", 'been')\n",
      "('ke', 'haters?')\n",
      "('lagi', 'pengen?')\n",
      "('fell', 'asleep')\n",
      "('wake', 'up')\n",
      "('te', 'amo')\n",
      "('un', 'canal')\n",
      "('buy', 'jack')\n",
      "(\"i'd\", 'rather')\n",
      "(\"jack's\", 'new')\n",
      "('cada', 'vez')\n",
      "(\"can't\", 'wait')\n",
      "('more', 'than')\n",
      "('hari', 'ini')\n",
      "('so', 'much')\n",
      "('puta', 'madre')\n",
      "('las', '24')\n",
      "('free', 'agent')\n",
      "('meu', 'deus')\n",
      "('te', 'invito')\n",
      "('canada', 'day')\n",
      "('habis', 'buat')\n",
      "('right', 'now.')\n",
      "('tal', 'vez')\n",
      "('otra', 'vez')\n",
      "('horas,', 'te')\n",
      "('hi', 'boys!')\n",
      "('punya', 'sahabat')\n",
      "('happy', 'canada')\n",
      "('sem', 'sono')\n",
      "('better', 'than')\n",
      "('vou', 'dormir')\n",
      "('follow', 'me')\n",
      "('cek', 'dm')\n",
      "('buy', 'doing')\n",
      "('new', 'song!')\n",
      "('las', 'cosas')\n",
      "('falling', 'asleep')\n",
      "('late', 'night')\n",
      "('feel', 'like')\n",
      "('going', 'to')\n"
     ]
    }
   ],
   "source": [
    "# sort bigrams in chi2_per_bigram by their Chi-square from highest to lowest. Show the top 100 bigrams.\n",
    "print(\"**************Based on Chi-square **********\")\n",
    "chi_top = []\n",
    "for bigram, freq in sorted(chi_tweet.items(), key = lambda x: x[1], reverse = True)[:100]:\n",
    "    print(bigram)\n",
    "    chi_top.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.tepar: 147\n",
      "c.ngumpul2: 147\n",
      "a.jalan2: 147\n",
      "b.tepar: 147\n",
      "pengen?: 159\n",
      "a.jalan2: 147\n",
      "luke: 3283\n",
      "hemmings: 2440\n",
      "a.ya: 210\n",
      "b.gak: 191\n",
      "teen: 736\n",
      "wolf: 663\n",
      "taco: 351\n",
      "bell: 273\n",
      "testing: 712\n",
      "1404190823: 349\n",
      "hobby: 219\n",
      "lobby: 161\n",
      "24: 794\n",
      "horas,: 406\n",
      "peanut: 140\n",
      "butter: 174\n",
      "testing: 712\n",
      "1404191460: 301\n",
      "hannah: 205\n",
      "montana: 135\n",
      "ice: 732\n",
      "cream: 443\n",
      "terlatih: 234\n",
      "sakit: 653\n",
      "michael: 1040\n",
      "clifford: 378\n",
      "boa: 816\n",
      "noite: 604\n",
      "gugu: 171\n",
      "morreu: 376\n",
      "free: 2419\n",
      "agency: 719\n",
      "harry: 399\n",
      "potter: 114\n"
     ]
    }
   ],
   "source": [
    "#Frequency of word in top20 bigram of chi_tweet\n",
    "for bgram in chi_top[:20]:\n",
    "    for x in bgram:\n",
    "        print(\"{}:\".format(x),itemset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Based on Mutual information**********\n",
      "('i', 'a')\n",
      "('i', 'the')\n",
      "('luke', 'hemmings')\n",
      "('you', 'i')\n",
      "('a', 'a')\n",
      "('me', 'i')\n",
      "('is', 'i')\n",
      "('to', 'a')\n",
      "('please', 'follow')\n",
      "('you', 'the')\n",
      "('you', 'you')\n",
      "('to', 'and')\n",
      "('follow', 'me')\n",
      "('and', 'to')\n",
      "('going', 'to')\n",
      "('it', 'i')\n",
      "('go', 'buy')\n",
      "('you', 'a')\n",
      "('so', 'much')\n",
      "('from', '5sos')\n",
      "('i', 'so')\n",
      "('me', 'the')\n",
      "('right', 'now')\n",
      "('me', 'you')\n",
      "('hemmings', 'from')\n",
      "('on', 'i')\n",
      "('you', 'to')\n",
      "('to', 'you')\n",
      "('no', 'i')\n",
      "('me', 'a')\n",
      "('me', 'my')\n",
      "('you', 'my')\n",
      "('happy', 'birthday')\n",
      "('new', 'song')\n",
      "('and', 'me')\n",
      "('a', 'lot')\n",
      "('in', 'to')\n",
      "('i', 'love')\n",
      "('is', 'to')\n",
      "('and', 'a')\n",
      "('this', 'i')\n",
      "('feel', 'like')\n",
      "('is', 'me')\n",
      "('is', 'you')\n",
      "('voy', 'a')\n",
      "('you', 'is')\n",
      "('it', 'the')\n",
      "('me', 'is')\n",
      "('me', 'to')\n",
      "('to', 'no')\n",
      "('a', 'no')\n",
      "('want', 'to')\n",
      "('to', 'it')\n",
      "('free', 'agency')\n",
      "('i', 'hate')\n",
      "('if', 'you')\n",
      "('it', 'a')\n",
      "('have', 'i')\n",
      "('that', 'to')\n",
      "('at', 'least')\n",
      "('so', 'the')\n",
      "('in', 'you')\n",
      "('the', 'best')\n",
      "('need', 'to')\n",
      "('trying', 'to')\n",
      "('wake', 'up')\n",
      "('is', 'and')\n",
      "('i', \"don't\")\n",
      "('that', 'a')\n",
      "('i', 'not')\n",
      "('teen', 'wolf')\n",
      "('it', 'you')\n",
      "('be', 'to')\n",
      "(\"i've\", 'been')\n",
      "('to', 'that')\n",
      "('i', 'want')\n",
      "('a', 'que')\n",
      "('in', 'me')\n",
      "('and', 'is')\n",
      "('more', 'than')\n",
      "('to', 'my')\n",
      "('on', 'to')\n",
      "('i', 'be')\n",
      "(\"can't\", 'wait')\n",
      "('i', 'are')\n",
      "('i', 'need')\n",
      "('fall', 'asleep')\n",
      "('the', 'same')\n",
      "('you', 'no')\n",
      "('i', 'am')\n",
      "('lo', 'que')\n",
      "('and', 'the')\n",
      "('te', 'amo')\n",
      "('up', 'i')\n",
      "('que', 'a')\n",
      "('in', 'the')\n",
      "('to', 'just')\n",
      "('you', \"i'm\")\n",
      "('to', 'but')\n",
      "('doing', 'it')\n"
     ]
    }
   ],
   "source": [
    "# sort bigrams in mi_per_bigram by their mutual information from highest to lowest. Show the top 100 bigrams.\n",
    "print(\"**************Based on Mutual information**********\")\n",
    "mut_top =[]\n",
    "for bigram, freq in sorted(mi_tweet.items(), key = lambda x: x[1], reverse = True)[:100]:\n",
    "    print(bigram)\n",
    "    mut_top.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 161290\n",
      "a: 108676\n",
      "i: 161290\n",
      "the: 99682\n",
      "luke: 3283\n",
      "hemmings: 2440\n",
      "you: 86025\n",
      "i: 161290\n",
      "a: 108676\n",
      "a: 108676\n",
      "me: 80856\n",
      "i: 161290\n",
      "is: 58984\n",
      "i: 161290\n",
      "to: 108698\n",
      "a: 108676\n",
      "please: 9079\n",
      "follow: 12510\n",
      "you: 86025\n",
      "the: 99682\n",
      "you: 86025\n",
      "you: 86025\n",
      "to: 108698\n",
      "and: 67236\n",
      "follow: 12510\n",
      "me: 80856\n",
      "and: 67236\n",
      "to: 108698\n",
      "going: 9055\n",
      "to: 108698\n",
      "it: 45851\n",
      "i: 161290\n",
      "go: 19582\n",
      "buy: 6080\n",
      "you: 86025\n",
      "a: 108676\n",
      "so: 41260\n",
      "much: 8250\n",
      "from: 11501\n",
      "5sos: 2972\n"
     ]
    }
   ],
   "source": [
    "#Frequency of word in top20 bigram of mi_tweet\n",
    "for bgram in mut_top[:20]:\n",
    "    for x in bgram:\n",
    "        print(\"{}:\".format(x),itemset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointwise Mutual Information vs Chi-square:72\n",
      "Pointwise Mutual Information vs Mutual information:4\n",
      "Mutual information vs Chi-square:21\n"
     ]
    }
   ],
   "source": [
    "#compute bigram set in both two top lists\n",
    "\n",
    "count =0\n",
    "for item in chi_top:\n",
    "    if item in pmi_top:\n",
    "        count+=1\n",
    "print (\"Pointwise Mutual Information vs Chi-square:{}\".format(count) )\n",
    "\n",
    "count =0\n",
    "for item in mut_top:\n",
    "    if item in pmi_top:\n",
    "        count+=1\n",
    "print (\"Pointwise Mutual Information vs Mutual information:{}\".format(count) )\n",
    "\n",
    "count =0\n",
    "for item in chi_top:\n",
    "    if item in mut_top:\n",
    "        count+=1\n",
    "print (\"Mutual information vs Chi-square:{}\".format(count) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
